{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels\n",
    "                ):\n",
    "        super(CBAM,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.avgpool = AdaptiveAvgPool2d(output_size = (1,1))\n",
    "        self.maxpool = AdaptiveMaxPool2d(output_size = (1,1))\n",
    "        self.linear = nn.Sequential(\n",
    "            Linear(in_channels,in_channels//2),\n",
    "            Linear(in_channels//2,in_channels)\n",
    "        )\n",
    "        self.relu = ReLU(inplace = True)\n",
    "        self.avgpool1d = AdaptiveAvgPool1d(output_size = 1)\n",
    "        self.maxpool1d = AdaptiveMaxPool1d(output_size = 1)\n",
    "        self.conv = Conv2d(2,1,3,1,1)\n",
    "        self.sigmoid = Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x1 = self.avgpool(x).squeeze(2).squeeze(2)\n",
    "        x2 = self.maxpool(x).squeeze(2).squeeze(2)\n",
    "        x3 = self.linear(x1)\n",
    "        x4 = self.linear(x2)\n",
    "        x5 = self.relu(x3+x4).unsqueeze(-1).unsqueeze(-1)\n",
    "        x6 = self.in_channels*x5/x5.sum(1).unsqueeze(-1)\n",
    "        y = torch.mul(x,x6)\n",
    "        y1 = self.avgpool1d(y.view(x.shape[0],-1,x.shape[1]))\n",
    "        y2 = self.maxpool1d(y.view(x.shape[0],-1,x.shape[1]))\n",
    "        y3 = torch.cat((y1,y2),dim = 2).permute(0,2,1).view(x.shape[0],2,x.shape[2],x.shape[3])\n",
    "        y4 = self.conv(y3)\n",
    "        y5 = self.sigmoid(y4)\n",
    "        a = y5.view(x.shape[0],-1).sum(1)\n",
    "        y6 = x.shape[2]*x.shape[3]*y5/a.view(x.shape[0],1,1,1)\n",
    "        y = torch.mul(y,y6)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModule(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 s = 2\n",
    "                 ):\n",
    "        super(GhostModule,self).__init__()\n",
    "        self.primary_conv = nn.Sequential(\n",
    "            Conv2d(in_channels,out_channels//s,1,1,bias=False),\n",
    "            BatchNorm2d(out_channels//2)\n",
    "        )\n",
    "        self.cheap_operation = nn.Sequential(\n",
    "            Conv2d(out_channels//s,(out_channels//s)*(s-1),3,1,1,groups=out_channels//s,bias=False),\n",
    "            BatchNorm2d((out_channels//s)*(s-1))\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        x = torch.cat((x1,x2),dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostBottleneck(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 exp = 3,\n",
    "                 attention = False\n",
    "                 ):\n",
    "        super(GhostBottleneck,self).__init__()\n",
    "        if stride==1:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                GhostModule(in_channels,in_channels*exp),\n",
    "                ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                GhostModule(in_channels,in_channels*exp),\n",
    "                ReLU(inplace=True),\n",
    "                Conv2d(in_channels*exp,in_channels*exp,3,stride=stride,padding=1,groups=in_channels*exp, bias=False),\n",
    "                BatchNorm2d(in_channels*exp),\n",
    "                ReLU(inplace=True)\n",
    "            )\n",
    "        if attention==True:\n",
    "            self.CBAM = CBAM(in_channels*exp)\n",
    "        else:\n",
    "            self.CBAM = nn.Sequential()\n",
    "        self.conv2 = GhostModule(in_channels*exp,out_channels)\n",
    "        if stride==1 and in_channels==out_channels:\n",
    "            self.residual = nn.Sequential()\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                Conv2d(in_channels,in_channels,3,stride=stride,padding=1,groups=in_channels, bias=False),\n",
    "                BatchNorm2d(in_channels),\n",
    "                Conv2d(in_channels,out_channels,1,1,bias=False),\n",
    "                BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.CBAM(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x + residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GhostNet,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            Conv2d(5,16,3,2,1,bias=False),\n",
    "            BatchNorm2d(16),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            GhostBottleneck(16,16,1,1,False),\n",
    "            GhostBottleneck(16,24,3,2,False),\n",
    "            \n",
    "            GhostBottleneck(24,24,3,1,False),\n",
    "            GhostBottleneck(24,40,3,2,True),\n",
    "            \n",
    "            GhostBottleneck(40,40,3,1,True),\n",
    "            GhostBottleneck(40,80,6,2,False),\n",
    "            \n",
    "            GhostBottleneck(80,80,3,1,False),\n",
    "            GhostBottleneck(80,120,4,1,True),\n",
    "            GhostBottleneck(120,160,4,2,True),\n",
    "            \n",
    "            GhostBottleneck(160,160,4,1,False),\n",
    "            GhostBottleneck(160,160,4,1,True),\n",
    "            \n",
    "            Conv2d(160,960,1,1,bias=False),\n",
    "            BatchNorm2d(960),\n",
    "            ReLU(inplace=True),\n",
    "            AdaptiveAvgPool2d((1, 1)),\n",
    "            Conv2d(960,1280,1,1,bias=True),\n",
    "            ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            Dropout(0.5),\n",
    "            Linear(1280,3)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
